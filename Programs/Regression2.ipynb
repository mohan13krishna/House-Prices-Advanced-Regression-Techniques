{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5, 
   "id": "8a2503eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Stacking CV score: 0.10591 (std: 0.01383)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "New submission created! Submit to Kaggle to check your score.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import ElasticNet, Lasso, Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "test_ID = test['Id']\n",
    "\n",
    "# Remove outliers (GrLivArea > 4000 and SalePrice < 300000)\n",
    "train = train[~((train['GrLivArea'] > 4000) & (train['SalePrice'] < 300000))]\n",
    "\n",
    "# Feature engineering\n",
    "all_data = pd.concat((train.drop(['Id', 'SalePrice'], axis=1), test.drop('Id', axis=1))).reset_index(drop=True)\n",
    "\n",
    "# Ensure numeric columns for age calculations\n",
    "all_data['YrSold'] = all_data['YrSold'].astype(float)\n",
    "all_data['YearBuilt'] = all_data['YearBuilt'].astype(float)\n",
    "all_data['YearRemodAdd'] = all_data['YearRemodAdd'].astype(float)\n",
    "\n",
    "# Advanced features\n",
    "all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\n",
    "all_data['HouseAge'] = all_data['YrSold'] - all_data['YearBuilt']\n",
    "all_data['RemodAge'] = all_data['YrSold'] - all_data['YearRemodAdd']\n",
    "all_data['QualCond'] = all_data['OverallQual'] * all_data['OverallCond']\n",
    "\n",
    "# Handle missing values\n",
    "# KNN Imputer for LotFrontage\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "all_data['LotFrontage'] = imputer.fit_transform(all_data[['LotFrontage']])[:, 0]\n",
    "\n",
    "# Fill other missing values\n",
    "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "all_data[numeric_feats] = all_data[numeric_feats].fillna(0)\n",
    "categorical_feats = all_data.dtypes[all_data.dtypes == \"object\"].index\n",
    "all_data[categorical_feats] = all_data[categorical_feats].fillna('None')\n",
    "\n",
    "# Skew transformation for numeric features\n",
    "skewed_feats = all_data[numeric_feats].apply(lambda x: x.skew()).sort_values(ascending=False)\n",
    "skewness = skewed_feats[skewed_feats > 0.75].index\n",
    "all_data[skewness] = np.log1p(all_data[skewness])\n",
    "\n",
    "# Target encoding for Neighborhood (mean SalePrice per neighborhood from train)\n",
    "neigh_map = train.groupby('Neighborhood')['SalePrice'].mean().to_dict()\n",
    "all_data['Neighborhood_Encoded'] = all_data['Neighborhood'].map(neigh_map)\n",
    "all_data['Neighborhood_Encoded'] = all_data['Neighborhood_Encoded'].fillna(train['SalePrice'].mean())  # Fix: Use train SalePrice mean\n",
    "\n",
    "# One-hot encoding for categoricals\n",
    "all_data = pd.get_dummies(all_data.drop('Neighborhood', axis=1))  # Drop Neighborhood since encoded\n",
    "all_data = all_data.fillna(all_data.mean())\n",
    "\n",
    "# Split back to train/test\n",
    "ntrain = train.shape[0]\n",
    "X = all_data[:ntrain]\n",
    "X_test = all_data[ntrain:]\n",
    "y = np.log1p(train['SalePrice'])  # Log transform target\n",
    "\n",
    "# Define base models\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha=0.0005, random_state=1))\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=0.9, random_state=3))\n",
    "GBoost = GradientBoostingRegressor(n_estimators=2000, learning_rate=0.05, max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, loss='huber', random_state=5)\n",
    "model_xgb = XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, learning_rate=0.05, max_depth=3,\n",
    "                         min_child_weight=1.7817, n_estimators=1500, reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                         subsample=0.5213, verbosity=0, random_state=7, n_jobs=-1)\n",
    "model_lgb = LGBMRegressor(objective='regression', num_leaves=5, learning_rate=0.05, n_estimators=600,\n",
    "                          max_bin=55, bagging_fraction=0.8, bagging_freq=5, feature_fraction=0.2319,\n",
    "                          feature_fraction_seed=9, bagging_seed=9, min_data_in_leaf=6, min_sum_hessian_in_leaf=11)\n",
    "model_cat = CatBoostRegressor(iterations=1000, learning_rate=0.05, depth=6, silent=True, random_seed=42)\n",
    "\n",
    "# Stacking setup with Lasso meta-learner\n",
    "estimators = [\n",
    "    ('lasso', lasso),\n",
    "    ('enet', ENet),\n",
    "    ('gboost', GBoost),\n",
    "    ('xgb', model_xgb),\n",
    "    ('lgb', model_lgb),\n",
    "    ('cat', model_cat)\n",
    "]\n",
    "stack = StackingRegressor(estimators=estimators, final_estimator=Lasso(alpha=0.0005), cv=10, n_jobs=-1)\n",
    "\n",
    "# Local CV evaluation (RMSLE)\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(10, shuffle=True, random_state=42)\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=kf))\n",
    "    return rmse\n",
    "\n",
    "score = rmsle_cv(stack)\n",
    "print(f\"Stacking CV score: {score.mean():.5f} (std: {score.std():.5f})\")\n",
    "\n",
    "# Fit and predict\n",
    "stack.fit(X, y)\n",
    "preds = np.expm1(stack.predict(X_test))\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\"Id\": test_ID, \"SalePrice\": preds})\n",
    "submission.to_csv(\"new_submission.csv\", index=False)\n",
    "print(\"New submission created! Submit to Kaggle to check your score.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
