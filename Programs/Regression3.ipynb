{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7c1d962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.25, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.25, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.25, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.25, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.25, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Stacking CV score: 0.11211 (std: 0.00792)\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.25, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.25\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Blended submission created! Submit to Kaggle to check your score.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "test_ID = test['Id']\n",
    "\n",
    "# Remove outliers (GrLivArea > 4000 and SalePrice < 300000)\n",
    "train = train[~((train['GrLivArea'] > 4000) & (train['SalePrice'] < 300000))]\n",
    "\n",
    "# Load previous submission for blending\n",
    "prev_submission = pd.read_csv('new_submission.csv')  # Replace with your 0.11868 submission file\n",
    "\n",
    "# Feature engineering\n",
    "all_data = pd.concat((train.drop(['Id', 'SalePrice'], axis=1), test.drop('Id', axis=1))).reset_index(drop=True)\n",
    "\n",
    "# Ensure numeric columns\n",
    "all_data['YrSold'] = all_data['YrSold'].astype(float)\n",
    "all_data['YearBuilt'] = all_data['YearBuilt'].astype(float)\n",
    "all_data['YearRemodAdd'] = all_data['YearRemodAdd'].astype(float)\n",
    "\n",
    "# Advanced features\n",
    "all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\n",
    "all_data['HouseAge'] = all_data['YrSold'] - all_data['YearBuilt']\n",
    "all_data['RemodAge'] = all_data['YrSold'] - all_data['YearRemodAdd']\n",
    "all_data['QualCond'] = all_data['OverallQual'] * all_data['OverallCond']\n",
    "all_data['TotalBath'] = all_data['FullBath'] + all_data['BsmtFullBath'] + 0.5 * (all_data['HalfBath'] + all_data['BsmtHalfBath'])\n",
    "all_data['TotalPorchSF'] = all_data['OpenPorchSF'] + all_data['EnclosedPorch'] + all_data['3SsnPorch'] + all_data['ScreenPorch']\n",
    "\n",
    "# Handle missing values\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "all_data['LotFrontage'] = imputer.fit_transform(all_data[['LotFrontage']])[:, 0]\n",
    "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "all_data[numeric_feats] = all_data[numeric_feats].fillna(0)\n",
    "categorical_feats = all_data.dtypes[all_data.dtypes == \"object\"].index\n",
    "all_data[categorical_feats] = all_data[categorical_feats].fillna('None')\n",
    "\n",
    "# Skew transformation\n",
    "skewed_feats = all_data[numeric_feats].apply(lambda x: x.skew()).sort_values(ascending=False)\n",
    "skewness = skewed_feats[skewed_feats > 0.75].index\n",
    "all_data[skewness] = np.log1p(all_data[skewness])\n",
    "\n",
    "# Ordinal encoding for Neighborhood (instead of target encoding)\n",
    "neigh_order = train.groupby('Neighborhood')['SalePrice'].median().sort_values().index\n",
    "neigh_map = {neigh: i for i, neigh in enumerate(neigh_order)}\n",
    "all_data['Neighborhood_Encoded'] = all_data['Neighborhood'].map(neigh_map).fillna(len(neigh_order))\n",
    "\n",
    "# One-hot encoding for categoricals\n",
    "all_data = pd.get_dummies(all_data.drop('Neighborhood', axis=1))\n",
    "all_data = all_data.fillna(all_data.mean())\n",
    "\n",
    "# Split back to train/test\n",
    "ntrain = train.shape[0]\n",
    "X = all_data[:ntrain]\n",
    "X_test = all_data[ntrain:]\n",
    "y = np.log1p(train['SalePrice'])\n",
    "\n",
    "# Define base models (simplified ensemble)\n",
    "model_xgb = XGBRegressor(colsample_bytree=0.5, learning_rate=0.05, max_depth=3,\n",
    "                         n_estimators=1000, reg_alpha=0.5, reg_lambda=1.0,\n",
    "                         subsample=0.6, verbosity=0, random_state=7, n_jobs=-1)\n",
    "model_lgb = LGBMRegressor(objective='regression', num_leaves=5, learning_rate=0.05, n_estimators=500,\n",
    "                          max_bin=55, bagging_fraction=0.8, bagging_freq=5, feature_fraction=0.25,\n",
    "                          min_data_in_leaf=6, min_sum_hessian_in_leaf=10, random_state=42)\n",
    "model_cat = CatBoostRegressor(iterations=800, learning_rate=0.05, depth=6, silent=True, random_seed=42)\n",
    "\n",
    "# Stacking setup with Ridge meta-learner\n",
    "estimators = [\n",
    "    ('xgb', model_xgb),\n",
    "    ('lgb', model_lgb),\n",
    "    ('cat', model_cat)\n",
    "]\n",
    "stack = StackingRegressor(estimators=estimators, final_estimator=Ridge(alpha=1.0), cv=5, n_jobs=-1)\n",
    "\n",
    "# Local CV evaluation (RMSLE)\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(5, shuffle=True, random_state=42)\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=kf))\n",
    "    return rmse\n",
    "\n",
    "score = rmsle_cv(stack)\n",
    "print(f\"Stacking CV score: {score.mean():.5f} (std: {score.std():.5f})\")\n",
    "\n",
    "# Fit and predict\n",
    "stack.fit(X, y)\n",
    "preds = np.expm1(stack.predict(X_test))\n",
    "\n",
    "# Blend with previous submission (0.7 new + 0.3 previous)\n",
    "blended_preds = 0.7 * preds + 0.3 * prev_submission['SalePrice'].values\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\"Id\": test_ID, \"SalePrice\": blended_preds})\n",
    "submission.to_csv(\"blended_submission.csv\", index=False)\n",
    "print(\"Blended submission created! Submit to Kaggle to check your score.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
